{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMQhk43Lu85S",
        "outputId": "1f02ce3c-5a8b-42f7-df4b-dcd73db9fe78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.4.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.53)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.53.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.53.0)\n",
            "Collecting langchain-core<2.0.0,>=1.1.0 (from langchain)\n",
            "  Downloading langchain_core-1.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (15.0.1)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.12)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.6.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-4.0.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.4.1-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.52.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.1.2-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m475.8/475.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, requests, pypdf, pyngrok, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, pydeck, dataclasses-json, langchain-core, streamlit, langchain-text-splitters, langchain-google-genai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.1 filetype-1.2.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.2 langchain-google-genai-4.0.0 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 pydeck-0.9.1 pyngrok-7.5.0 pypdf-6.4.1 requests-2.32.5 streamlit-1.52.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-community langchain-google-genai faiss-cpu pypdf streamlit pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_AUTH_TOKEN = \"36b3aogkVI94W0EneDY5gf9fecE_2hzPMZTmH54ooQqtGR3T\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "1SNYkS24wF6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LFZN8-MuDK0",
        "outputId": "16dbd0e0-f7b6-49d1-85bc-9b13bcc03a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
            "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "import streamlit as st\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader # Make sure Docx2txtLoader is imported\n",
        "# ... other imports (st, RecursiveCharacterTextSplitter, etc.)\n",
        "import os\n",
        "\n",
        "# ------------------- PAGE CONFIG -------------------\n",
        "st.set_page_config(page_title=\"UrPdfFriend\", layout=\"wide\")\n",
        "\n",
        "\n",
        "# ------------------- CUSTOM UI CSS -------------------\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "\n",
        "html, body, .stApp {\n",
        "    background: linear-gradient(135deg, #4A148C, #880E4F, #FF00FF, #00FFFF); /* CHANGED COLORS */\n",
        "    background-size: 400% 400%;\n",
        "    animation: gradientBG 12s ease infinite;\n",
        "    color: white !important;\n",
        "}\n",
        "\n",
        "@keyframes gradientBG {\n",
        "    0% { background-position: 0% 50%; }\n",
        "    50% { background-position: 100% 50%; }\n",
        "    100% { background-position: 0% 50%; }\n",
        "}\n",
        "\n",
        ".block-container {\n",
        "    background: transparent !important;\n",
        "    padding-top: 1rem;\n",
        "}\n",
        "\n",
        "/* Header Image */\n",
        ".header-container {\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "\n",
        ".header-img {\n",
        "    width: 60%;\n",
        "    border-radius: 16px;\n",
        "    box-shadow: 0 0 25px rgba(0,0,0,0.45);\n",
        "}\n",
        "\n",
        "/* Chat bubbles */\n",
        ".chat-message {\n",
        "    border-radius: 12px;\n",
        "    padding: 14px 18px;\n",
        "    margin-bottom: 1rem;\n",
        "    max-width: 80%;\n",
        "    backdrop-filter: blur(10px);\n",
        "    color: #fff;\n",
        "}\n",
        "\n",
        ".user-msg {\n",
        "    background: rgba(0, 180, 255, 0.35);\n",
        "    margin-left: auto;\n",
        "}\n",
        "\n",
        ".bot-msg {\n",
        "    background: rgba(255, 255, 255, 0.15);\n",
        "    border: 1px solid rgba(255,255,255,0.25);\n",
        "}\n",
        "\n",
        "/* File Uploader */\n",
        ".stFileUploader {\n",
        "    background: rgba(255, 255, 255, 0.08);\n",
        "    padding: 14px;\n",
        "    border-radius: 12px;\n",
        "    backdrop-filter: blur(6px);\n",
        "}\n",
        "\n",
        ".stFileUploader label div {\n",
        "    color: #ffffff !important;\n",
        "    font-size: 18px !important;\n",
        "}\n",
        "\n",
        "/* Chat input */\n",
        ".stChatInput input {\n",
        "    background-color: rgba(0,0,0,0.35) !important;\n",
        "    color: white !important;\n",
        "    border-radius: 10px !important;\n",
        "    border: 1px solid rgba(255,255,255,0.25) !important;\n",
        "}\n",
        "\n",
        "/* Remove Streamlit white header */\n",
        "div[data-testid=\"stHeader\"] {\n",
        "    background: transparent !important;\n",
        "}\n",
        "\n",
        "/* Remove top toolbar */\n",
        "div[data-testid=\"stToolbar\"] {\n",
        "    display: none !important;\n",
        "}\n",
        "\n",
        "/* Fix Browse Files button style */\n",
        ".stFileUploader button[kind=\"secondary\"] {\n",
        "    background-color: rgba(0, 0, 0, 0.55) !important;\n",
        "    color: #ffffff !important;\n",
        "    border-radius: 10px !important;\n",
        "    padding: 8px 16px !important;\n",
        "    border: 1px solid rgba(255,255,255,0.25) !important;\n",
        "}\n",
        "\n",
        "/* Hover effect */\n",
        ".stFileUploader button[kind=\"secondary\"]:hover {\n",
        "    background-color: rgba(0, 0, 0, 0.75) !important;\n",
        "    color: #ffffff !important;\n",
        "    border: 1px solid rgba(255,255,255,0.45) !important;\n",
        "    cursor: pointer !important;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# ------------------- HEADER IMAGE -------------------\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <div class='header-container'>\n",
        "        <img src=\"https://tse3.mm.bing.net/th/id/OIP.egCUtrB2A1lXPg9qhwCxlAHaHa?w=187&h=186&c=7&r=0&o=7&dpr=1.5&pid=1.7&rm=3\" class=\"header-img\">\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.markdown(\"<h1 style='text-align:center; color:white;'>ğŸ“š Reading is hard? Lemme Help you!</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<p style='text-align:center; color:#f0f0f0; font-size:18px;'>Ask anything from your uploaded PDF with accurate citations</p>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# ------------------- MODIFIED RAG LOGIC FOR MULTIPLE FILES -------------------\n",
        "\n",
        "# 1. Change file_uploader to accept multiple files (PDF and DOCX)\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Upload PDF(s) or Word Document(s)\",\n",
        "    type=[\"pdf\", \"docx\"], # Added 'docx'\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "if uploaded_files:\n",
        "    # 2. Process all uploaded files\n",
        "    all_pages = []\n",
        "\n",
        "    # Use st.spinner for a better UX while processing files\n",
        "    with st.spinner(f\"Processing {len(uploaded_files)} file(s)...\"): # Updated count and text\n",
        "        for uploaded_file in uploaded_files:\n",
        "            # Save the file to a temporary location\n",
        "            temp_file_name = uploaded_file.name # Generic file name variable\n",
        "            file_extension = temp_file_name.split('.')[-1].lower() # Get file extension\n",
        "\n",
        "            with open(temp_file_name, \"wb\") as f:\n",
        "                f.write(uploaded_file.read())\n",
        "\n",
        "            # Use the appropriate loader based on the file extension\n",
        "            if file_extension == \"pdf\":\n",
        "                loader = PyPDFLoader(temp_file_name)\n",
        "            elif file_extension == \"docx\":\n",
        "                loader = Docx2txtLoader(temp_file_name)\n",
        "            else:\n",
        "                # Should not happen due to 'type' filter, but good practice\n",
        "                st.warning(f\"Skipping unsupported file: {temp_file_name}\")\n",
        "                os.remove(temp_file_name)\n",
        "                continue\n",
        "\n",
        "            pages = loader.load()\n",
        "            all_pages.extend(pages)\n",
        "\n",
        "            # Clean up the temporary file\n",
        "            os.remove(temp_file_name)\n",
        "\n",
        "        # Ensure content was successfully extracted\n",
        "        if not all_pages:\n",
        "             st.error(\"No content could be extracted from the uploaded files.\")\n",
        "             st.stop() # Stop further execution if no documents are loaded\n",
        "\n",
        "\n",
        "        # 3. Split documents from all pages combined\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=800,\n",
        "            chunk_overlap=150\n",
        "        )\n",
        "\n",
        "        documents = splitter.split_documents(all_pages)\n",
        "\n",
        "        # 4. Continue with RAG setup using the combined documents\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = \"Auth_token\"\n",
        "\n",
        "        model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "        # Create a single Vector Store from all documents\n",
        "        vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "        retriever = vectorstore.as_retriever(search_type=\"similarity\", k=5)\n",
        "\n",
        "        rag_prompt = PromptTemplate(\n",
        "            input_variables=[\"context\", \"question\"],\n",
        "            template=\"\"\"\n",
        "You must answer the user's question ONLY using the text in the given context.\n",
        "STRICT RULES:\n",
        "- DO NOT paraphrase.\n",
        "- Use ONLY exact sentences/phrases present in the context.\n",
        "- If answer requires 1 mark, give very short exact lines.\n",
        "- If answer requires 10 marks, give long exact lines.\n",
        "- Add page number citations like: (Source: X)\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "ANSWER (with source):\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "        # The format_docs function is updated to be robust for documents with or without page numbers (e.g., Word documents)\n",
        "        def format_docs(docs):\n",
        "            # This links to the original document source and page number (if available)\n",
        "            return \"\\n\\n\".join([f\"(Source: {d.metadata.get('source')} Page: {d.metadata.get('page', 'N/A')}):\\n{d.page_content}\" for d in docs])\n",
        "\n",
        "        rag_chain = (\n",
        "            RunnableParallel({\n",
        "                \"context\": RunnableLambda(lambda x: retriever.invoke(x[\"question\"])) | RunnableLambda(format_docs),\n",
        "                \"question\": RunnableLambda(lambda x: x[\"question\"])\n",
        "            })\n",
        "            | rag_prompt\n",
        "            | model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        # Initialize history if it's the first run with files\n",
        "        if \"history\" not in st.session_state:\n",
        "            st.session_state.history = []\n",
        "\n",
        "        # CHAT HISTORY UI (Moved inside the 'if uploaded_files' block)\n",
        "        for msg in st.session_state.history:\n",
        "            bubble_class = \"user-msg\" if msg[\"role\"] == \"user\" else \"bot-msg\"\n",
        "            st.markdown(\n",
        "                f\"<div class='chat-message {bubble_class}'>{msg['content']}</div>\",\n",
        "                unsafe_allow_html=True\n",
        "            )\n",
        "\n",
        "        user_prompt = st.chat_input(\"Ask anything from the files...\") # Updated chat input text\n",
        "\n",
        "        if user_prompt:\n",
        "            st.session_state.history.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "            st.markdown(f\"<div class='chat-message user-msg'>{user_prompt}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                response = rag_chain.invoke({\"question\": user_prompt})\n",
        "\n",
        "            st.markdown(f\"<div class='chat-message bot-msg'>{response}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "else:\n",
        "    # 5. Handle the case where no files are uploaded\n",
        "    st.info(\"Upload one or more PDF or Word documents to start chatting.\") # Updated info message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca5c852-99bb-4d7c-8773-aafb292ea5fd",
        "id": "S_y1g9Jg4Jtw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate any existing ngrok tunnels started by pyngrok\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "!streamlit run my_app.py --server.port 8501 &> /dev/null &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM7ZFNgnw_kF",
        "outputId": "d289cc47-1042-4171-e8b5-f1f5a3c2f4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://sewerlike-predecisively-beckett.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}
